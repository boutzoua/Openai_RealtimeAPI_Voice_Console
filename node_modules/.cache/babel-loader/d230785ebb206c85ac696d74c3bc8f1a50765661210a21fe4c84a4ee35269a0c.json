{"ast":null,"code":"import { noteFrequencies, noteFrequencyLabels, voiceFrequencies, voiceFrequencyLabels } from './constants.js';\n\n/**\r\n * Output of AudioAnalysis for the frequency domain of the audio\r\n * @typedef {Object} AudioAnalysisOutputType\r\n * @property {Float32Array} values Amplitude of this frequency between {0, 1} inclusive\r\n * @property {number[]} frequencies Raw frequency bucket values\r\n * @property {string[]} labels Labels for the frequency bucket values\r\n */\n\n/**\r\n * Analyzes audio for visual output\r\n * @class\r\n */\nexport class AudioAnalysis {\n  /**\r\n   * Retrieves frequency domain data from an AnalyserNode adjusted to a decibel range\r\n   * returns human-readable formatting and labels\r\n   * @param {AnalyserNode} analyser\r\n   * @param {number} sampleRate\r\n   * @param {Float32Array} [fftResult]\r\n   * @param {\"frequency\"|\"music\"|\"voice\"} [analysisType]\r\n   * @param {number} [minDecibels] default -100\r\n   * @param {number} [maxDecibels] default -30\r\n   * @returns {AudioAnalysisOutputType}\r\n   */\n  static getFrequencies(analyser, sampleRate, fftResult, analysisType = 'frequency', minDecibels = -100, maxDecibels = -30) {\n    if (!fftResult) {\n      fftResult = new Float32Array(analyser.frequencyBinCount);\n      analyser.getFloatFrequencyData(fftResult);\n    }\n    const nyquistFrequency = sampleRate / 2;\n    const frequencyStep = 1 / fftResult.length * nyquistFrequency;\n    let outputValues;\n    let frequencies;\n    let labels;\n    if (analysisType === 'music' || analysisType === 'voice') {\n      const useFrequencies = analysisType === 'voice' ? voiceFrequencies : noteFrequencies;\n      const aggregateOutput = Array(useFrequencies.length).fill(minDecibels);\n      for (let i = 0; i < fftResult.length; i++) {\n        const frequency = i * frequencyStep;\n        const amplitude = fftResult[i];\n        for (let n = useFrequencies.length - 1; n >= 0; n--) {\n          if (frequency > useFrequencies[n]) {\n            aggregateOutput[n] = Math.max(aggregateOutput[n], amplitude);\n            break;\n          }\n        }\n      }\n      outputValues = aggregateOutput;\n      frequencies = analysisType === 'voice' ? voiceFrequencies : noteFrequencies;\n      labels = analysisType === 'voice' ? voiceFrequencyLabels : noteFrequencyLabels;\n    } else {\n      outputValues = Array.from(fftResult);\n      frequencies = outputValues.map((_, i) => frequencyStep * i);\n      labels = frequencies.map(f => `${f.toFixed(2)} Hz`);\n    }\n    // We normalize to {0, 1}\n    const normalizedOutput = outputValues.map(v => {\n      return Math.max(0, Math.min((v - minDecibels) / (maxDecibels - minDecibels), 1));\n    });\n    const values = new Float32Array(normalizedOutput);\n    return {\n      values,\n      frequencies,\n      labels\n    };\n  }\n\n  /**\r\n   * Creates a new AudioAnalysis instance for an HTMLAudioElement\r\n   * @param {HTMLAudioElement} audioElement\r\n   * @param {AudioBuffer|null} [audioBuffer] If provided, will cache all frequency domain data from the buffer\r\n   * @returns {AudioAnalysis}\r\n   */\n  constructor(audioElement, audioBuffer = null) {\n    this.fftResults = [];\n    if (audioBuffer) {\n      /**\r\n       * Modified from\r\n       * https://stackoverflow.com/questions/75063715/using-the-web-audio-api-to-analyze-a-song-without-playing\r\n       *\r\n       * We do this to populate FFT values for the audio if provided an `audioBuffer`\r\n       * The reason to do this is that Safari fails when using `createMediaElementSource`\r\n       * This has a non-zero RAM cost so we only opt-in to run it on Safari, Chrome is better\r\n       */\n      const {\n        length,\n        sampleRate\n      } = audioBuffer;\n      const offlineAudioContext = new OfflineAudioContext({\n        length,\n        sampleRate\n      });\n      const source = offlineAudioContext.createBufferSource();\n      source.buffer = audioBuffer;\n      const analyser = offlineAudioContext.createAnalyser();\n      analyser.fftSize = 8192;\n      analyser.smoothingTimeConstant = 0.1;\n      source.connect(analyser);\n      // limit is :: 128 / sampleRate;\n      // but we just want 60fps - cuts ~1s from 6MB to 1MB of RAM\n      const renderQuantumInSeconds = 1 / 60;\n      const durationInSeconds = length / sampleRate;\n      const analyze = index => {\n        const suspendTime = renderQuantumInSeconds * index;\n        if (suspendTime < durationInSeconds) {\n          offlineAudioContext.suspend(suspendTime).then(() => {\n            const fftResult = new Float32Array(analyser.frequencyBinCount);\n            analyser.getFloatFrequencyData(fftResult);\n            this.fftResults.push(fftResult);\n            analyze(index + 1);\n          });\n        }\n        if (index === 1) {\n          offlineAudioContext.startRendering();\n        } else {\n          offlineAudioContext.resume();\n        }\n      };\n      source.start(0);\n      analyze(1);\n      this.audio = audioElement;\n      this.context = offlineAudioContext;\n      this.analyser = analyser;\n      this.sampleRate = sampleRate;\n      this.audioBuffer = audioBuffer;\n    } else {\n      const audioContext = new AudioContext();\n      const track = audioContext.createMediaElementSource(audioElement);\n      const analyser = audioContext.createAnalyser();\n      analyser.fftSize = 8192;\n      analyser.smoothingTimeConstant = 0.1;\n      track.connect(analyser);\n      analyser.connect(audioContext.destination);\n      this.audio = audioElement;\n      this.context = audioContext;\n      this.analyser = analyser;\n      this.sampleRate = this.context.sampleRate;\n      this.audioBuffer = null;\n    }\n  }\n\n  /**\r\n   * Gets the current frequency domain data from the playing audio track\r\n   * @param {\"frequency\"|\"music\"|\"voice\"} [analysisType]\r\n   * @param {number} [minDecibels] default -100\r\n   * @param {number} [maxDecibels] default -30\r\n   * @returns {AudioAnalysisOutputType}\r\n   */\n  getFrequencies(analysisType = 'frequency', minDecibels = -100, maxDecibels = -30) {\n    let fftResult = null;\n    if (this.audioBuffer && this.fftResults.length) {\n      const pct = this.audio.currentTime / this.audio.duration;\n      const index = Math.min(pct * this.fftResults.length | 0, this.fftResults.length - 1);\n      fftResult = this.fftResults[index];\n    }\n    return AudioAnalysis.getFrequencies(this.analyser, this.sampleRate, fftResult, analysisType, minDecibels, maxDecibels);\n  }\n\n  /**\r\n   * Resume the internal AudioContext if it was suspended due to the lack of\r\n   * user interaction when the AudioAnalysis was instantiated.\r\n   * @returns {Promise<true>}\r\n   */\n  async resumeIfSuspended() {\n    if (this.context.state === 'suspended') {\n      await this.context.resume();\n    }\n    return true;\n  }\n}\nglobalThis.AudioAnalysis = AudioAnalysis;","map":{"version":3,"names":["noteFrequencies","noteFrequencyLabels","voiceFrequencies","voiceFrequencyLabels","AudioAnalysis","getFrequencies","analyser","sampleRate","fftResult","analysisType","minDecibels","maxDecibels","Float32Array","frequencyBinCount","getFloatFrequencyData","nyquistFrequency","frequencyStep","length","outputValues","frequencies","labels","useFrequencies","aggregateOutput","Array","fill","i","frequency","amplitude","n","Math","max","from","map","_","f","toFixed","normalizedOutput","v","min","values","constructor","audioElement","audioBuffer","fftResults","offlineAudioContext","OfflineAudioContext","source","createBufferSource","buffer","createAnalyser","fftSize","smoothingTimeConstant","connect","renderQuantumInSeconds","durationInSeconds","analyze","index","suspendTime","suspend","then","push","startRendering","resume","start","audio","context","audioContext","AudioContext","track","createMediaElementSource","destination","pct","currentTime","duration","resumeIfSuspended","state","globalThis"],"sources":["/Users/smartleet/Desktop/Openai_RealtimeAPI_Voice_Console/src/lib/wavtools/lib/analysis/audio_analysis.js"],"sourcesContent":["import {\r\n  noteFrequencies,\r\n  noteFrequencyLabels,\r\n  voiceFrequencies,\r\n  voiceFrequencyLabels,\r\n} from './constants.js';\r\n\r\n/**\r\n * Output of AudioAnalysis for the frequency domain of the audio\r\n * @typedef {Object} AudioAnalysisOutputType\r\n * @property {Float32Array} values Amplitude of this frequency between {0, 1} inclusive\r\n * @property {number[]} frequencies Raw frequency bucket values\r\n * @property {string[]} labels Labels for the frequency bucket values\r\n */\r\n\r\n/**\r\n * Analyzes audio for visual output\r\n * @class\r\n */\r\nexport class AudioAnalysis {\r\n  /**\r\n   * Retrieves frequency domain data from an AnalyserNode adjusted to a decibel range\r\n   * returns human-readable formatting and labels\r\n   * @param {AnalyserNode} analyser\r\n   * @param {number} sampleRate\r\n   * @param {Float32Array} [fftResult]\r\n   * @param {\"frequency\"|\"music\"|\"voice\"} [analysisType]\r\n   * @param {number} [minDecibels] default -100\r\n   * @param {number} [maxDecibels] default -30\r\n   * @returns {AudioAnalysisOutputType}\r\n   */\r\n  static getFrequencies(\r\n    analyser,\r\n    sampleRate,\r\n    fftResult,\r\n    analysisType = 'frequency',\r\n    minDecibels = -100,\r\n    maxDecibels = -30,\r\n  ) {\r\n    if (!fftResult) {\r\n      fftResult = new Float32Array(analyser.frequencyBinCount);\r\n      analyser.getFloatFrequencyData(fftResult);\r\n    }\r\n    const nyquistFrequency = sampleRate / 2;\r\n    const frequencyStep = (1 / fftResult.length) * nyquistFrequency;\r\n    let outputValues;\r\n    let frequencies;\r\n    let labels;\r\n    if (analysisType === 'music' || analysisType === 'voice') {\r\n      const useFrequencies =\r\n        analysisType === 'voice' ? voiceFrequencies : noteFrequencies;\r\n      const aggregateOutput = Array(useFrequencies.length).fill(minDecibels);\r\n      for (let i = 0; i < fftResult.length; i++) {\r\n        const frequency = i * frequencyStep;\r\n        const amplitude = fftResult[i];\r\n        for (let n = useFrequencies.length - 1; n >= 0; n--) {\r\n          if (frequency > useFrequencies[n]) {\r\n            aggregateOutput[n] = Math.max(aggregateOutput[n], amplitude);\r\n            break;\r\n          }\r\n        }\r\n      }\r\n      outputValues = aggregateOutput;\r\n      frequencies =\r\n        analysisType === 'voice' ? voiceFrequencies : noteFrequencies;\r\n      labels =\r\n        analysisType === 'voice' ? voiceFrequencyLabels : noteFrequencyLabels;\r\n    } else {\r\n      outputValues = Array.from(fftResult);\r\n      frequencies = outputValues.map((_, i) => frequencyStep * i);\r\n      labels = frequencies.map((f) => `${f.toFixed(2)} Hz`);\r\n    }\r\n    // We normalize to {0, 1}\r\n    const normalizedOutput = outputValues.map((v) => {\r\n      return Math.max(\r\n        0,\r\n        Math.min((v - minDecibels) / (maxDecibels - minDecibels), 1),\r\n      );\r\n    });\r\n    const values = new Float32Array(normalizedOutput);\r\n    return {\r\n      values,\r\n      frequencies,\r\n      labels,\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Creates a new AudioAnalysis instance for an HTMLAudioElement\r\n   * @param {HTMLAudioElement} audioElement\r\n   * @param {AudioBuffer|null} [audioBuffer] If provided, will cache all frequency domain data from the buffer\r\n   * @returns {AudioAnalysis}\r\n   */\r\n  constructor(audioElement, audioBuffer = null) {\r\n    this.fftResults = [];\r\n    if (audioBuffer) {\r\n      /**\r\n       * Modified from\r\n       * https://stackoverflow.com/questions/75063715/using-the-web-audio-api-to-analyze-a-song-without-playing\r\n       *\r\n       * We do this to populate FFT values for the audio if provided an `audioBuffer`\r\n       * The reason to do this is that Safari fails when using `createMediaElementSource`\r\n       * This has a non-zero RAM cost so we only opt-in to run it on Safari, Chrome is better\r\n       */\r\n      const { length, sampleRate } = audioBuffer;\r\n      const offlineAudioContext = new OfflineAudioContext({\r\n        length,\r\n        sampleRate,\r\n      });\r\n      const source = offlineAudioContext.createBufferSource();\r\n      source.buffer = audioBuffer;\r\n      const analyser = offlineAudioContext.createAnalyser();\r\n      analyser.fftSize = 8192;\r\n      analyser.smoothingTimeConstant = 0.1;\r\n      source.connect(analyser);\r\n      // limit is :: 128 / sampleRate;\r\n      // but we just want 60fps - cuts ~1s from 6MB to 1MB of RAM\r\n      const renderQuantumInSeconds = 1 / 60;\r\n      const durationInSeconds = length / sampleRate;\r\n      const analyze = (index) => {\r\n        const suspendTime = renderQuantumInSeconds * index;\r\n        if (suspendTime < durationInSeconds) {\r\n          offlineAudioContext.suspend(suspendTime).then(() => {\r\n            const fftResult = new Float32Array(analyser.frequencyBinCount);\r\n            analyser.getFloatFrequencyData(fftResult);\r\n            this.fftResults.push(fftResult);\r\n            analyze(index + 1);\r\n          });\r\n        }\r\n        if (index === 1) {\r\n          offlineAudioContext.startRendering();\r\n        } else {\r\n          offlineAudioContext.resume();\r\n        }\r\n      };\r\n      source.start(0);\r\n      analyze(1);\r\n      this.audio = audioElement;\r\n      this.context = offlineAudioContext;\r\n      this.analyser = analyser;\r\n      this.sampleRate = sampleRate;\r\n      this.audioBuffer = audioBuffer;\r\n    } else {\r\n      const audioContext = new AudioContext();\r\n      const track = audioContext.createMediaElementSource(audioElement);\r\n      const analyser = audioContext.createAnalyser();\r\n      analyser.fftSize = 8192;\r\n      analyser.smoothingTimeConstant = 0.1;\r\n      track.connect(analyser);\r\n      analyser.connect(audioContext.destination);\r\n      this.audio = audioElement;\r\n      this.context = audioContext;\r\n      this.analyser = analyser;\r\n      this.sampleRate = this.context.sampleRate;\r\n      this.audioBuffer = null;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Gets the current frequency domain data from the playing audio track\r\n   * @param {\"frequency\"|\"music\"|\"voice\"} [analysisType]\r\n   * @param {number} [minDecibels] default -100\r\n   * @param {number} [maxDecibels] default -30\r\n   * @returns {AudioAnalysisOutputType}\r\n   */\r\n  getFrequencies(\r\n    analysisType = 'frequency',\r\n    minDecibels = -100,\r\n    maxDecibels = -30,\r\n  ) {\r\n    let fftResult = null;\r\n    if (this.audioBuffer && this.fftResults.length) {\r\n      const pct = this.audio.currentTime / this.audio.duration;\r\n      const index = Math.min(\r\n        (pct * this.fftResults.length) | 0,\r\n        this.fftResults.length - 1,\r\n      );\r\n      fftResult = this.fftResults[index];\r\n    }\r\n    return AudioAnalysis.getFrequencies(\r\n      this.analyser,\r\n      this.sampleRate,\r\n      fftResult,\r\n      analysisType,\r\n      minDecibels,\r\n      maxDecibels,\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Resume the internal AudioContext if it was suspended due to the lack of\r\n   * user interaction when the AudioAnalysis was instantiated.\r\n   * @returns {Promise<true>}\r\n   */\r\n  async resumeIfSuspended() {\r\n    if (this.context.state === 'suspended') {\r\n      await this.context.resume();\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nglobalThis.AudioAnalysis = AudioAnalysis;\r\n"],"mappings":"AAAA,SACEA,eAAe,EACfC,mBAAmB,EACnBC,gBAAgB,EAChBC,oBAAoB,QACf,gBAAgB;;AAEvB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMC,aAAa,CAAC;EACzB;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,OAAOC,cAAcA,CACnBC,QAAQ,EACRC,UAAU,EACVC,SAAS,EACTC,YAAY,GAAG,WAAW,EAC1BC,WAAW,GAAG,CAAC,GAAG,EAClBC,WAAW,GAAG,CAAC,EAAE,EACjB;IACA,IAAI,CAACH,SAAS,EAAE;MACdA,SAAS,GAAG,IAAII,YAAY,CAACN,QAAQ,CAACO,iBAAiB,CAAC;MACxDP,QAAQ,CAACQ,qBAAqB,CAACN,SAAS,CAAC;IAC3C;IACA,MAAMO,gBAAgB,GAAGR,UAAU,GAAG,CAAC;IACvC,MAAMS,aAAa,GAAI,CAAC,GAAGR,SAAS,CAACS,MAAM,GAAIF,gBAAgB;IAC/D,IAAIG,YAAY;IAChB,IAAIC,WAAW;IACf,IAAIC,MAAM;IACV,IAAIX,YAAY,KAAK,OAAO,IAAIA,YAAY,KAAK,OAAO,EAAE;MACxD,MAAMY,cAAc,GAClBZ,YAAY,KAAK,OAAO,GAAGP,gBAAgB,GAAGF,eAAe;MAC/D,MAAMsB,eAAe,GAAGC,KAAK,CAACF,cAAc,CAACJ,MAAM,CAAC,CAACO,IAAI,CAACd,WAAW,CAAC;MACtE,KAAK,IAAIe,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGjB,SAAS,CAACS,MAAM,EAAEQ,CAAC,EAAE,EAAE;QACzC,MAAMC,SAAS,GAAGD,CAAC,GAAGT,aAAa;QACnC,MAAMW,SAAS,GAAGnB,SAAS,CAACiB,CAAC,CAAC;QAC9B,KAAK,IAAIG,CAAC,GAAGP,cAAc,CAACJ,MAAM,GAAG,CAAC,EAAEW,CAAC,IAAI,CAAC,EAAEA,CAAC,EAAE,EAAE;UACnD,IAAIF,SAAS,GAAGL,cAAc,CAACO,CAAC,CAAC,EAAE;YACjCN,eAAe,CAACM,CAAC,CAAC,GAAGC,IAAI,CAACC,GAAG,CAACR,eAAe,CAACM,CAAC,CAAC,EAAED,SAAS,CAAC;YAC5D;UACF;QACF;MACF;MACAT,YAAY,GAAGI,eAAe;MAC9BH,WAAW,GACTV,YAAY,KAAK,OAAO,GAAGP,gBAAgB,GAAGF,eAAe;MAC/DoB,MAAM,GACJX,YAAY,KAAK,OAAO,GAAGN,oBAAoB,GAAGF,mBAAmB;IACzE,CAAC,MAAM;MACLiB,YAAY,GAAGK,KAAK,CAACQ,IAAI,CAACvB,SAAS,CAAC;MACpCW,WAAW,GAAGD,YAAY,CAACc,GAAG,CAAC,CAACC,CAAC,EAAER,CAAC,KAAKT,aAAa,GAAGS,CAAC,CAAC;MAC3DL,MAAM,GAAGD,WAAW,CAACa,GAAG,CAAEE,CAAC,IAAK,GAAGA,CAAC,CAACC,OAAO,CAAC,CAAC,CAAC,KAAK,CAAC;IACvD;IACA;IACA,MAAMC,gBAAgB,GAAGlB,YAAY,CAACc,GAAG,CAAEK,CAAC,IAAK;MAC/C,OAAOR,IAAI,CAACC,GAAG,CACb,CAAC,EACDD,IAAI,CAACS,GAAG,CAAC,CAACD,CAAC,GAAG3B,WAAW,KAAKC,WAAW,GAAGD,WAAW,CAAC,EAAE,CAAC,CAC7D,CAAC;IACH,CAAC,CAAC;IACF,MAAM6B,MAAM,GAAG,IAAI3B,YAAY,CAACwB,gBAAgB,CAAC;IACjD,OAAO;MACLG,MAAM;MACNpB,WAAW;MACXC;IACF,CAAC;EACH;;EAEA;AACF;AACA;AACA;AACA;AACA;EACEoB,WAAWA,CAACC,YAAY,EAAEC,WAAW,GAAG,IAAI,EAAE;IAC5C,IAAI,CAACC,UAAU,GAAG,EAAE;IACpB,IAAID,WAAW,EAAE;MACf;AACN;AACA;AACA;AACA;AACA;AACA;AACA;MACM,MAAM;QAAEzB,MAAM;QAAEV;MAAW,CAAC,GAAGmC,WAAW;MAC1C,MAAME,mBAAmB,GAAG,IAAIC,mBAAmB,CAAC;QAClD5B,MAAM;QACNV;MACF,CAAC,CAAC;MACF,MAAMuC,MAAM,GAAGF,mBAAmB,CAACG,kBAAkB,CAAC,CAAC;MACvDD,MAAM,CAACE,MAAM,GAAGN,WAAW;MAC3B,MAAMpC,QAAQ,GAAGsC,mBAAmB,CAACK,cAAc,CAAC,CAAC;MACrD3C,QAAQ,CAAC4C,OAAO,GAAG,IAAI;MACvB5C,QAAQ,CAAC6C,qBAAqB,GAAG,GAAG;MACpCL,MAAM,CAACM,OAAO,CAAC9C,QAAQ,CAAC;MACxB;MACA;MACA,MAAM+C,sBAAsB,GAAG,CAAC,GAAG,EAAE;MACrC,MAAMC,iBAAiB,GAAGrC,MAAM,GAAGV,UAAU;MAC7C,MAAMgD,OAAO,GAAIC,KAAK,IAAK;QACzB,MAAMC,WAAW,GAAGJ,sBAAsB,GAAGG,KAAK;QAClD,IAAIC,WAAW,GAAGH,iBAAiB,EAAE;UACnCV,mBAAmB,CAACc,OAAO,CAACD,WAAW,CAAC,CAACE,IAAI,CAAC,MAAM;YAClD,MAAMnD,SAAS,GAAG,IAAII,YAAY,CAACN,QAAQ,CAACO,iBAAiB,CAAC;YAC9DP,QAAQ,CAACQ,qBAAqB,CAACN,SAAS,CAAC;YACzC,IAAI,CAACmC,UAAU,CAACiB,IAAI,CAACpD,SAAS,CAAC;YAC/B+C,OAAO,CAACC,KAAK,GAAG,CAAC,CAAC;UACpB,CAAC,CAAC;QACJ;QACA,IAAIA,KAAK,KAAK,CAAC,EAAE;UACfZ,mBAAmB,CAACiB,cAAc,CAAC,CAAC;QACtC,CAAC,MAAM;UACLjB,mBAAmB,CAACkB,MAAM,CAAC,CAAC;QAC9B;MACF,CAAC;MACDhB,MAAM,CAACiB,KAAK,CAAC,CAAC,CAAC;MACfR,OAAO,CAAC,CAAC,CAAC;MACV,IAAI,CAACS,KAAK,GAAGvB,YAAY;MACzB,IAAI,CAACwB,OAAO,GAAGrB,mBAAmB;MAClC,IAAI,CAACtC,QAAQ,GAAGA,QAAQ;MACxB,IAAI,CAACC,UAAU,GAAGA,UAAU;MAC5B,IAAI,CAACmC,WAAW,GAAGA,WAAW;IAChC,CAAC,MAAM;MACL,MAAMwB,YAAY,GAAG,IAAIC,YAAY,CAAC,CAAC;MACvC,MAAMC,KAAK,GAAGF,YAAY,CAACG,wBAAwB,CAAC5B,YAAY,CAAC;MACjE,MAAMnC,QAAQ,GAAG4D,YAAY,CAACjB,cAAc,CAAC,CAAC;MAC9C3C,QAAQ,CAAC4C,OAAO,GAAG,IAAI;MACvB5C,QAAQ,CAAC6C,qBAAqB,GAAG,GAAG;MACpCiB,KAAK,CAAChB,OAAO,CAAC9C,QAAQ,CAAC;MACvBA,QAAQ,CAAC8C,OAAO,CAACc,YAAY,CAACI,WAAW,CAAC;MAC1C,IAAI,CAACN,KAAK,GAAGvB,YAAY;MACzB,IAAI,CAACwB,OAAO,GAAGC,YAAY;MAC3B,IAAI,CAAC5D,QAAQ,GAAGA,QAAQ;MACxB,IAAI,CAACC,UAAU,GAAG,IAAI,CAAC0D,OAAO,CAAC1D,UAAU;MACzC,IAAI,CAACmC,WAAW,GAAG,IAAI;IACzB;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;EACErC,cAAcA,CACZI,YAAY,GAAG,WAAW,EAC1BC,WAAW,GAAG,CAAC,GAAG,EAClBC,WAAW,GAAG,CAAC,EAAE,EACjB;IACA,IAAIH,SAAS,GAAG,IAAI;IACpB,IAAI,IAAI,CAACkC,WAAW,IAAI,IAAI,CAACC,UAAU,CAAC1B,MAAM,EAAE;MAC9C,MAAMsD,GAAG,GAAG,IAAI,CAACP,KAAK,CAACQ,WAAW,GAAG,IAAI,CAACR,KAAK,CAACS,QAAQ;MACxD,MAAMjB,KAAK,GAAG3B,IAAI,CAACS,GAAG,CACnBiC,GAAG,GAAG,IAAI,CAAC5B,UAAU,CAAC1B,MAAM,GAAI,CAAC,EAClC,IAAI,CAAC0B,UAAU,CAAC1B,MAAM,GAAG,CAC3B,CAAC;MACDT,SAAS,GAAG,IAAI,CAACmC,UAAU,CAACa,KAAK,CAAC;IACpC;IACA,OAAOpD,aAAa,CAACC,cAAc,CACjC,IAAI,CAACC,QAAQ,EACb,IAAI,CAACC,UAAU,EACfC,SAAS,EACTC,YAAY,EACZC,WAAW,EACXC,WACF,CAAC;EACH;;EAEA;AACF;AACA;AACA;AACA;EACE,MAAM+D,iBAAiBA,CAAA,EAAG;IACxB,IAAI,IAAI,CAACT,OAAO,CAACU,KAAK,KAAK,WAAW,EAAE;MACtC,MAAM,IAAI,CAACV,OAAO,CAACH,MAAM,CAAC,CAAC;IAC7B;IACA,OAAO,IAAI;EACb;AACF;AAEAc,UAAU,CAACxE,aAAa,GAAGA,aAAa","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}